{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbcba36-ee9f-4834-94f1-77de754ed63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded artifacts:\n",
      " - XGB reg: savings_xgb_reg.pkl (features=25)\n",
      " - Scaler:  scaler_05B.pkl\n",
      " - KMeans:  kmeans_05B.pkl\n",
      " - Goal clf: loaded\n"
     ]
    }
   ],
   "source": [
    "# 06_financial_advice_engine — Cell 1: Load artifacts\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "\n",
    "paths = {\n",
    "    \"xgb_reg\": MODEL_DIR / \"savings_xgb_reg.pkl\",\n",
    "    \"xgb_reg_cols\": MODEL_DIR / \"savings_xgb_reg_columns.pkl\",\n",
    "    \"scaler\": MODEL_DIR / \"scaler_05B.pkl\",\n",
    "    \"kmeans\": MODEL_DIR / \"kmeans_05B.pkl\",\n",
    "    \"goal_clf\": MODEL_DIR / \"savings_goal_xgb.pkl\",\n",
    "    \"goal_clf_cols\": MODEL_DIR / \"savings_goal_xgb_columns.pkl\",\n",
    "}\n",
    "\n",
    "# required\n",
    "xgb_reg = joblib.load(paths[\"xgb_reg\"])\n",
    "xgb_features = joblib.load(paths[\"xgb_reg_cols\"])\n",
    "scaler = joblib.load(paths[\"scaler\"])\n",
    "kmeans = joblib.load(paths[\"kmeans\"])\n",
    "\n",
    "# optional\n",
    "try:\n",
    "    goal_clf = joblib.load(paths[\"goal_clf\"])\n",
    "    goal_features = joblib.load(paths[\"goal_clf_cols\"])\n",
    "except Exception:\n",
    "    goal_clf, goal_features = None, None\n",
    "\n",
    "print(\"✅ Loaded artifacts:\")\n",
    "print(f\" - XGB reg: {paths['xgb_reg'].name} (features={len(xgb_features)})\")\n",
    "print(f\" - Scaler:  {paths['scaler'].name}\")\n",
    "print(f\" - KMeans:  {paths['kmeans'].name}\")\n",
    "print(\" - Goal clf:\", \"loaded\" if goal_clf is not None else \"not loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4f76b6-8665-4df1-a9c8-4e2e54a8161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_financial_advice_engine — Cell 2: One-hot + align utility\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def one_hot_align(df_in: pd.DataFrame, required_cols: list[str], cat_cols=(\"Occupation\",\"City_Tier\")) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One-hot encode categorical columns and align to required_cols.\n",
    "    Adds missing cols as 0 and ensures exact column order.\n",
    "    \"\"\"\n",
    "    # Encode only if the column is present\n",
    "    use_cats = [c for c in cat_cols if c in df_in.columns]\n",
    "    df_enc = pd.get_dummies(df_in.copy(), columns=use_cats, dtype=int)\n",
    "\n",
    "    # Add missing training columns\n",
    "    for col in required_cols:\n",
    "        if col not in df_enc.columns:\n",
    "            df_enc[col] = 0\n",
    "\n",
    "    # Keep order identical to training\n",
    "    return df_enc[required_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56d5bcd-878a-49f8-ab78-548f36ea2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_financial_advice_engine — Cell 3: Predict savings with XGB and attach\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_savings_xgb(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses loaded xgb_reg + xgb_features to predict savings.\n",
    "    Returns a copy with Pred_Savings_XGB attached.\n",
    "    \"\"\"\n",
    "    X = one_hot_align(df_raw, xgb_features)\n",
    "    yhat = xgb_reg.predict(X)\n",
    "    yhat = np.maximum(yhat, 0).round(2)  # no negatives, tidy to cents\n",
    "\n",
    "    out = df_raw.copy()\n",
    "    out[\"Pred_Savings_XGB\"] = yhat\n",
    "\n",
    "    # Optional quick evaluation if ground truth present\n",
    "    if \"Desired_Savings\" in out.columns:\n",
    "        mae = float(np.mean(np.abs(out[\"Pred_Savings_XGB\"] - out[\"Desired_Savings\"])))\n",
    "        print(f\"MAE vs Desired_Savings: {mae:.2f}\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addacd19-a7c3-478f-8617-682f5c85acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_financial_advice_engine — Cell 4: Assign cluster & persona\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Features used for clustering (same flavor as your 05 notebook, with model signal)\n",
    "CLUSTER_FEATURES = [\n",
    "    \"Income\",\n",
    "    \"Disposable_Income\",\n",
    "    \"Pred_Savings_XGB\",  # model-driven signal\n",
    "    \"Groceries\",\n",
    "    \"Transport\",\n",
    "    \"Entertainment\",\n",
    "]\n",
    "\n",
    "PERSONA_NAMES = {\n",
    "    0: \"Budget-conscious majority\",\n",
    "    1: \"Comfortable middle\",\n",
    "    2: \"Affluent elite\",\n",
    "}\n",
    "\n",
    "def assign_cluster_and_persona(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses loaded scaler + kmeans to assign cluster labels, then maps personas by\n",
    "    ranking clusters on Pred_Savings_XGB (low→mid→high).\n",
    "    \"\"\"\n",
    "    if not set(CLUSTER_FEATURES).issubset(df_in.columns):\n",
    "        missing = [c for c in CLUSTER_FEATURES if c not in df_in.columns]\n",
    "        raise KeyError(f\"Missing required columns for clustering: {missing}\")\n",
    "\n",
    "    X = df_in[CLUSTER_FEATURES].astype(float)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    labels = kmeans.predict(X_scaled).astype(int)\n",
    "\n",
    "    out = df_in.copy()\n",
    "    out[\"Cluster\"] = labels\n",
    "\n",
    "    # Rank clusters by model-predicted savings to assign personas deterministically\n",
    "    order = (\n",
    "        out.groupby(\"Cluster\")[\"Pred_Savings_XGB\"]\n",
    "           .mean()\n",
    "           .sort_values()           # low → mid → high\n",
    "           .index.tolist()\n",
    "    )\n",
    "    rank_map = {cl: rank for rank, cl in enumerate(order)}\n",
    "    out[\"Persona\"] = out[\"Cluster\"].map(rank_map).map(PERSONA_NAMES)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35191b85-91b6-44e5-9dde-5e5f1f466cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_financial_advice_engine — Cell 5: Goal achievement classification (optional)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_goal(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses loaded goal_clf (+ goal_features) to estimate the probability of achieving\n",
    "    the user's savings goal. Adds:\n",
    "      - Goal_Prob: probability of positive class (achieve)\n",
    "      - Goal_Label: 'Likely' / 'Unlikely' based on a threshold\n",
    "    If goal_clf is not loaded, returns input unchanged.\n",
    "    \"\"\"\n",
    "    if goal_clf is None or goal_features is None:\n",
    "        print(\"ℹ️ Goal classifier not loaded; skipping classification.\")\n",
    "        return df_in.copy()\n",
    "\n",
    "    # One-hot align to classifier feature space\n",
    "    Xg = one_hot_align(df_in, goal_features)\n",
    "\n",
    "    # Some classifiers expose predict_proba; fall back to decision_function if needed\n",
    "    if hasattr(goal_clf, \"predict_proba\"):\n",
    "        probs = goal_clf.predict_proba(Xg)[:, 1]\n",
    "    elif hasattr(goal_clf, \"decision_function\"):\n",
    "        # Min-max to [0,1] as a rough probability proxy\n",
    "        scores = goal_clf.decision_function(Xg)\n",
    "        mn, mx = scores.min(), scores.max()\n",
    "        probs = (scores - mn) / (mx - mn + 1e-9)\n",
    "    else:\n",
    "        # Last resort: binary prediction only\n",
    "        preds = goal_clf.predict(Xg)\n",
    "        probs = preds.astype(float)\n",
    "\n",
    "    out = df_in.copy()\n",
    "    out[\"Goal_Prob\"] = np.round(probs, 3)\n",
    "    out[\"Goal_Label\"] = np.where(out[\"Goal_Prob\"] >= 0.5, \"Likely\", \"Unlikely\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a956de26-8f16-4429-8f77-1217de7e13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_financial_advice_engine — Cell 6: Run the advice engine end-to-end\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def run_advice_engine(df_input: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "      1) Predict savings (XGB)\n",
    "      2) Assign cluster & persona (scaler + kmeans)\n",
    "      3) (Optional) Classify goal likelihood\n",
    "    Returns a copy of the input with new columns appended.\n",
    "    \"\"\"\n",
    "    df_step1 = predict_savings_xgb(df_input)\n",
    "    df_step2 = assign_cluster_and_persona(df_step1)\n",
    "    df_final = classify_goal(df_step2)  # no-op if goal_clf wasn't loaded\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91309031-6687-4bce-84bc-f7389ceed9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
